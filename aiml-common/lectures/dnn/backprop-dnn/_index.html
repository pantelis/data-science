
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Backpropagation in Deep Neural Networks &#8212; Introduction to Data Science</title>
    
  <link href="../../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://pantelis.dev/aiml-common/lectures/dnn/backprop-dnn/_index.html" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Introduction to Convolutional Neural Networks" href="../../cnn/cnn-intro/_index.html" />
    <link rel="prev" title="Introduction to Backpropagation" href="../backprop-intro/_index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Data Science</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../intro.html">
   Introduction to Data Science
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to Data Science
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../ai-intro/course-introduction/_index.html">
   Course Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ai-intro/data-science-360/_index.html">
   Data Science 360
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Probabilistic Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-math/probability/_index.html">
   Probability Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../entropy/_index.html">
   Entropy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pgm/bayesian-inference/_index.html">
   Bayesian Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../classification/covid19-antibody-test/_index.html">
   COVID-19 Antibody Test
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pgm/bayesian-coin/_index.html">
   Bayesian Coin Flipping
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  The Learning Problem
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../regression/linear-regression/_index.html">
   Linear Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../optimization/sgd/_index.html">
   Stochastic Gradient Descent
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Classification
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../classification/classification-intro/_index.html">
   Introduction to Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../classification/logistic-regression/_index.html">
   Logistic Regression
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Trees and Intelligence of the Crowds
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../decision-trees/_index.html">
   Decision Trees
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ensemble/_index.html">
   Ensemble Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ensemble/random-forests/_index.html">
   Random Forests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ensemble/boosting/_index.html">
   Boosting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ensemble/boosting-workshop/_index.html">
   Boosting workshop
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Non-Parametric Methods
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../unsupervised/k-means/_index.html">
   K-means Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../density-estimation/knn/_index.html">
   k-Nearest Neighbors (kNN) Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../density-estimation/knn-workshop/_index.html">
   kNN Workshop
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Neural Networks
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../classification/perceptron/_index.html">
   The Neuron (Perceptron)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dnn-intro/_index.html">
   Deep Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../backprop-intro/_index.html">
   Introduction to Backpropagation
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Backpropagation in Deep Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cnn/cnn-intro/_index.html">
   Introduction to Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cnn/cnn-layers/_index.html">
   CNN Architectures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cnn/cnn-example-architectures/_index.html">
   CNN Example Architectures
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Dimensionality Reduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../recommenders/recommenders-intro/_index.html">
   Recommender System Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../recommenders/netflix/_index.html">
   The Netflix Prize and Singular Value Decomposition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pca/_index.html">
   Principal Component Analysis (PCA)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Math Background
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../linear-algebra/vectors/_index.html">
   Vectors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../linear-algebra/matrices/_index.html">
   Matrices
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-math/calculus/_index.html">
   Calculus
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../python/_index.html">
   Learn Python
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../../_sources/aiml-common/lectures/dnn/backprop-dnn/_index.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/jupyter-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Faiml-common/lectures/dnn/backprop-dnn/_index.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/executablebooks/jupyter-book/edit/master/docs/aiml-common/lectures/dnn/backprop-dnn/_index.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dnn-gates">
   DNN Gates
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#backpropagation-through-non-linear-units">
   Backpropagation through non-linear units
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Backpropagation in Deep Neural Networks</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dnn-gates">
   DNN Gates
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#backpropagation-through-non-linear-units">
   Backpropagation through non-linear units
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="backpropagation-in-deep-neural-networks">
<h1>Backpropagation in Deep Neural Networks<a class="headerlink" href="#backpropagation-in-deep-neural-networks" title="Permalink to this headline">¶</a></h1>
<p>Following the [introductory]() section, we have seen that backpropagation is a procedure that involves the repetitive application of the chain rule. Let us now treat its application to neural networks and the gates that we usually meet there. In DNNs we are dealing with vectors, matrices and in general <a class="reference external" href="https://www.tensorflow.org/guide/tensor">tensors</a> and therefore its required to review first how we can expand on the template above for these data types.</p>
<p><img alt="backpropagation-dnn" src="../../../../_images/backpropagation-dnn.png" /></p>
<div class="section" id="dnn-gates">
<h2>DNN Gates<a class="headerlink" href="#dnn-gates" title="Permalink to this headline">¶</a></h2>
<p>In the following we heavily borrow from <a class="reference external" href="https://web.stanford.edu/class/cs224n/readings/gradient-notes.pdf">this</a> text. The basic building block of vectorized gradients is the <em>Jacobian Matrix</em>. In the [introductory]() section we dealt with functions <span class="math notranslate nohighlight">\(f: \mathbb{R}^2 \to \mathbb{R}\)</span>. Suppose that we have a more complicated function <span class="math notranslate nohighlight">\(\bm f: \mathbb{R}^n \to \mathbb{R}^m\)</span> that maps a vector of length <span class="math notranslate nohighlight">\(n\)</span> to a vector of length <span class="math notranslate nohighlight">\(m\)</span>:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\bm f(\bm x) = [f_1(x_1, ..., x_n), f_2(x_1, ..., x_n), ..., f_m(x_1, ..., x_n)]$$. \\Then its Jacobian is:\\\begin{split}$$\frac{\partial \bm f}{\partial \bm x} = 
\begin{bmatrix} \frac{\partial f_1}{\partial x_1} &amp; \dots &amp; \frac{\partial f_1}{\partial x_n} \\\\ \vdots &amp; \dots &amp; \vdots \\\\ \frac{\partial f_m}{\partial x_1} &amp; \dots &amp; \frac{\partial f_m}{\partial x_n} \end{bmatrix}\end{split}\end{aligned}\end{align} \]</div>
<p>The Jacobian matrix will be useful for us because we can apply the chain rule to a vector-valued function just by multiplying Jacobians.</p>
<p>As a little illustration of this, suppose we have a function <span class="math notranslate nohighlight">\(f(\mathbf x) = [f_1(x), f_2(x)]\)</span> taking a scalar to a vector of size 2 and a function <span class="math notranslate nohighlight">\(g(\mathbf y) = [g_1(y_1, y_2), g_2(y_1, y_2)]\)</span> taking a vector of size two to a vector of size two. Now let’s compose them to get <span class="math notranslate nohighlight">\(g(x) = [g_1(f_1(x), f_2(x)), g_2(f_1(x), f_2(x))]\)</span>. Using the regular chain rule, we can compute the derivative of <span class="math notranslate nohighlight">\(g\)</span> as the Jacobian</p>
<div class="math notranslate nohighlight">
\[\begin{split}\frac{\partial g}{\partial x} = \begin{bmatrix} \frac{\partial}{\partial x}g_1(f_1(x), f_2(x))  \\\\ \frac{\partial} {\partial x}g_2(f_1(x), f_2(x))  \\\\ \end{bmatrix} =  \begin{bmatrix} \frac{\partial{g_1}}{\partial f_1}\frac{\partial{f_1}}{\partial x} + \frac{\partial{g_1}}{\partial f_2}\frac{\partial{f_2}}{\partial x}   \\\\ \frac{\partial{g_2}}{\partial f_1}\frac{\partial{f_1}}{\partial x} + \frac{\partial{g_2}}{\partial f_2}\frac{\partial{f_2}}{\partial x}  \end{bmatrix}\end{split}\]</div>
<p>And we see this is the same as multiplying the two Jacobians:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\frac{\partial{g}}{\partial x} = \frac{\partial{ g}}{\partial f}\frac{\partial{f}}{\partial x} = \begin{bmatrix} \frac{\partial{g_1}}{\partial f_1} &amp; \frac{\partial{g_1}}{\partial f_2} \\\\ \frac{\partial{g_2}}{\partial f_1} &amp; \frac{\partial{g_2}}{\partial f_2} \\\\ \end{bmatrix} \begin{bmatrix} \frac{\partial{f_1}}{\partial x} \\\\ \frac{\partial{f_2}}{\partial x} \\\\ \end{bmatrix}\end{split}\]</div>
<p><a class="reference external" href="http://cs231n.stanford.edu/vecDerivs.pdf">This</a> is also another instructive summary that help us understand how to calculate the local gradients involved and the gate templates (identities) summarized below that are routinely found in neural network backpropagation calculations. Assume that  with <span class="math notranslate nohighlight">\(\mathbf W \in \mathbb{R}^{n \times m}, \mathbf x \in \mathbb{R}^m\)</span>.</p>
<p><em>Tables of Gates and Gradients used in the backpropagation of deep neural networks</em></p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Gate</p></th>
<th class="head"><p>Solution</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><img alt="identity1" src="../../../../_images/identity1.png" /> <br> <span class="math notranslate nohighlight">\(\mathbf z = \mathbf W \mathbf x\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{\partial \mathbf z}{\partial \mathbf x} = \mathbf W\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><img alt="identity2" src="../../../../_images/identity2.png" /> <br> <span class="math notranslate nohighlight">\(\mathbf z = \mathbf x \mathbf W\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{\partial \mathbf z}{\partial \mathbf x} = \mathbf W^T\)</span></p></td>
</tr>
<tr class="row-even"><td><p><img alt="identity3" src="../../../../_images/identity3.png" /> <br> <span class="math notranslate nohighlight">\(\mathbf z =  \mathbf x\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{\partial \mathbf z}{\partial \mathbf x} = \mathbf I\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><img alt="identity4" src="../../../../_images/identity4.png" /> <br> <span class="math notranslate nohighlight">\(\mathbf z =  f(\mathbf x)\)</span> element-wise</p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{\partial \mathbf z}{\partial \mathbf x} = \text{Diag}[ f'(\mathbf x) ]\)</span></p></td>
</tr>
<tr class="row-even"><td><p><img alt="identity5" src="../../../../_images/identity5.png" /> <br> <span class="math notranslate nohighlight">\(\mathbf z = \mathbf W \mathbf x\)</span>, <span class="math notranslate nohighlight">\(\mathbf \delta =  \frac{\partial L}{\partial \mathbf z}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{\partial L}{\partial \mathbf W} = \mathbf \delta^T \mathbf x^T\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><img alt="identity6" src="../../../../_images/identity6.png" /> <br> <span class="math notranslate nohighlight">\(\mathbf z = \mathbf x \mathbf W\)</span>, <span class="math notranslate nohighlight">\(\mathbf \delta =  \frac{\partial L}{\partial \mathbf z}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{\partial L}{\partial \mathbf W} = \mathbf x^T \mathbf \delta\)</span></p></td>
</tr>
<tr class="row-even"><td><p><img alt="identity4" src="../../../../_images/identity7.png" /> <br> <span class="math notranslate nohighlight">\(\mathbf z = \mathbf W \mathbf x\)</span>, <span class="math notranslate nohighlight">\(\hat \mathbf y = \mathtt{softmax}(\mathbf z)\)</span>, <span class="math notranslate nohighlight">\(L=CE(\mathbf y , \hat \mathbf y )\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{\partial L}{\partial \mathbf z} = \hat \mathbf y - \mathbf y\)</span></p></td>
</tr>
</tbody>
</table>
<p>During the lecture we will go through an NN example on the whiteboard that will use these gate gradients for the estimation of the gradient of the loss with respect to its parameters using backpropagation.</p>
</div>
<div class="section" id="backpropagation-through-non-linear-units">
<h2>Backpropagation through non-linear units<a class="headerlink" href="#backpropagation-through-non-linear-units" title="Permalink to this headline">¶</a></h2>
<p>As shown <a class="reference external" href="https://medium.com/&#64;karpathy/yes-you-should-understand-backprop-e2f06eab496b">here</a>, you need to be watchful of the effects of the various non-linear gates on the gradient flow.</p>
<p>For <strong>sigmoid gate</strong>, if you are sloppy with the weight initialization or data preprocessing these non-linearities can “saturate” and entirely stop learning — your training loss will be flat and refuse to go down. If your weight matrix W is initialized too large, the output of the matrix multiply could have a very large range (e.g. numbers between -400 and 400), which will make all outputs in the vector z almost binary: either 1 or 0. But if that is the case, <span class="math notranslate nohighlight">\(z*(1-z)\)</span>, which is <strong>local</strong> gradient of the sigmoid non-linearity, will in both cases become zero (“vanish”), making the gradient for both x and W be zero. The rest of the backward pass will come out all zero from this point on due to multiplication in the chain rule.</p>
<p><img alt="sigmoid-derivative" src="../../../../_images/sigmoid-derivative.png" /></p>
<p>The <strong>ReLU gates</strong>, hide under the hood a max operator. The max operation routes the gradient. Unlike the add gate which distributed the gradient unchanged to all its inputs, the max gate distributes the gradient (unchanged) to exactly one of its inputs (the input that had the highest value during the forward pass). This is because the local gradient for a max gate is 1.0 for the highest value, and 0.0 for all other values. Notably, if a neuron gets clamped to zero in the forward pass (i.e. z=0, it doesn’t “fire”), then its weights will get zero gradient. This can lead to what is called the “dead ReLU” problem, where if a ReLU neuron is unfortunately initialized such that it never fires, or if a neuron’s weights ever get knocked off with a large update during training into this regime, then this neuron will remain permanently dead.</p>
<p><img alt="relu-derivative" src="../../../../_images/relu-derivative.png" /></p>
<p>Tensorflow can create a computational graph from the DNN model specification (python). These graphs can be visualized on the web UI with Tensorboard. Use the playground when you first learn about DNNs to understand the principles but dive into the Fashion MNIST using Tensorflow use case to understand the Tensorflow mechanics and how to debug Tensorflow python scripts both syntactically and logically. Logical debugging should happen using Tensorboard visualizations. Similarly with Pytorch if this is your framework choice.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./aiml-common/lectures/dnn/backprop-dnn"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../backprop-intro/_index.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Introduction to Backpropagation</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../../cnn/cnn-intro/_index.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Introduction to Convolutional Neural Networks</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Pantelis Monogioudis, Ph.D<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>